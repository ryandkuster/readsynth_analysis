{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# real snipen 2021 datasets\n",
    "# current_file = './snipen_16.csv'\n",
    "# current_file = './snipen_24.csv'\n",
    "# current_file = './snipen_25.csv'\n",
    "\n",
    "# simulated liu even dataset\n",
    "# current_file = './liu_sim_even.csv'\n",
    "\n",
    "# simulated helius datasets\n",
    "# current_file = './helius_ecori_agei_100K.csv'\n",
    "# current_file = './helius_ecori_msei_100K.csv'\n",
    "# current_file = './helius_hhai_agei_100K.csv'\n",
    "# current_file = './helius_hhai_msei_100K.csv'\n",
    "\n",
    "# current_file = './helius_ecori_agei.csv'\n",
    "# current_file = './helius_ecori_msei.csv'\n",
    "# current_file = './helius_hhai_agei.csv'\n",
    "# current_file = './helius_hhai_msei.csv'\n",
    "\n",
    "# current_file = './helius_ecori_agei_10M.csv'\n",
    "# current_file = './helius_ecori_msei_10M.csv'\n",
    "# current_file = './helius_hhai_agei_10M.csv'\n",
    "# current_file = './helius_hhai_msei_10M.csv'\n",
    "\n",
    "# current_file = './helius_ecori_agei_100M.csv'\n",
    "# current_file = './helius_ecori_msei_100M.csv'\n",
    "# current_file = './helius_hhai_agei_100M.csv'\n",
    "# current_file = './helius_hhai_msei_100M.csv'\n",
    "\n",
    "# current_file = './helius_ecori_msei_10M_lower.csv'\n",
    "# current_file = './helius_ecori_msei_10M_higher.csv'\n",
    "\n",
    "current_file = './liu_sim_10M_post_bracken.csv'\n",
    "\n",
    "\n",
    "df = pd.read_csv(current_file, index_col=0)\n",
    "\n",
    "kmers_ls = df.columns.to_list()[15:-1]\n",
    "kmers_ls = [i for i in kmers_ls if 'N' not in i]\n",
    "print(kmers_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the number of reads recovered after recreating fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all fragments with internal cut sites. This makes the ratio comparisons much simpler, as complete digest fragments will *always* occur at a higher ratio than the longer fragments that may contain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['internal']==0]\n",
    "p_tot_frag = int(df['observed'].sum())\n",
    "print(f'{p_tot_frag} total fragments observed')\n",
    "df.sort_values('rel_abund', inplace=True)\n",
    "p_uniq_frag = df.shape[0]\n",
    "print(f'{p_uniq_frag} unique fragments')\n",
    "p_taxa_no = len(df['genome'].unique())\n",
    "print(f'{p_taxa_no} taxa observed')\n",
    "gen_ls = list(df['genome'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ground truth list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ls = []\n",
    "for gen in gen_ls:\n",
    "    e = df[df['genome']==gen]['rel_abund'].unique()[0]\n",
    "    e_ls.append(float(e))\n",
    "\n",
    "print(len(e_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the ratio of taxa-to-taxa fragment counts for each fragment length\n",
    "\n",
    "Calculate all relative abundance comparisons by capturing the inter-taxa ratios for each fragment length. The average of these ratios will be used to determine the overall relative abundance of the taxa, because the ratios should hold regardless of the fragment size being taken into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ratios(tmp_df, gen_ls):\n",
    "    '''\n",
    "    for a given length of fragment, within each genome x, get the average\n",
    "    observed count as avg, then divide each observed count for every\n",
    "    genome by avg this average and save as a column named after x\n",
    "    '''\n",
    "    for gen in gen_ls:\n",
    "        avg = tmp_df[tmp_df['genome']==gen]['observed'].mean()\n",
    "        tmp_df[gen] = tmp_df['observed'] / avg\n",
    "    return tmp_df\n",
    "\n",
    "\n",
    "def scale_ratios(np_arr):\n",
    "    '''\n",
    "    this approach assumes the first column, first row is a reliable\n",
    "    representation of the real count data...\n",
    "    '''\n",
    "    rel_base = np_arr[0,0]\n",
    "    for idx, i in enumerate(np_arr[0,:]):\n",
    "        col_scale = rel_base/i\n",
    "        np_arr[:,idx] = np_arr[:,idx]*col_scale\n",
    "    return np_arr\n",
    "\n",
    "\n",
    "def get_max_idx(ratios_df):\n",
    "    max_ratios = ratios_df.count().max()\n",
    "    for idx, i in enumerate(ratios_df.columns.to_list()):\n",
    "        if ratios_df[i].count() == max_ratios:\n",
    "            max_genome = i\n",
    "            max_idx = idx\n",
    "    return max_idx\n",
    "\n",
    "\n",
    "def scale_ratios_to_max(np_ratios, max_idx):\n",
    "    np_arr = np.copy(np_ratios)\n",
    "    manp = np_arr[:,max_idx]\n",
    "\n",
    "    for idx, i in enumerate(np_arr.T):\n",
    "        col_scale = manp/i\n",
    "        np_arr[:,idx] = np.nanmean(col_scale)*i\n",
    "    return np_arr\n",
    "\n",
    "\n",
    "def average_over_columns(np_arr):\n",
    "    avg_ls = np.nanmean(np_arr, axis=1).tolist()\n",
    "    return avg_ls\n",
    "\n",
    "\n",
    "def return_rel_abund(o_ls):\n",
    "    rel_ls = []\n",
    "    for i in o_ls:\n",
    "        rel_ls.append(i/sum(o_ls))\n",
    "    return rel_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.copy()\n",
    "try:\n",
    "    test_df.drop(gen_ls, inplace=True, axis=1)\n",
    "except KeyError:\n",
    "    pass\n",
    "test_df = test_df.reindex(columns = test_df.columns.tolist() + gen_ls)\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for j in range(0, test_df['length'].max()+1):\n",
    "    if j % 100 == 0:\n",
    "        print(f'processing fragments of {j}bp')\n",
    "    tmp_df = test_df[test_df['length']==j].copy()\n",
    "    if tmp_df.shape[0] > 0:\n",
    "        tmp_df = process_ratios(tmp_df, gen_ls)\n",
    "        final_df = pd.concat([final_df, tmp_df])\n",
    "\n",
    "ratios_df = pd.DataFrame(0, index=gen_ls, columns=gen_ls)\n",
    "\n",
    "for gena in gen_ls:\n",
    "    for genb in gen_ls:\n",
    "        ratios_df.loc[gena, genb] = final_df[final_df['genome']==gena][genb].mean()\n",
    "\n",
    "np_ratios = np.array(ratios_df)\n",
    "# scaled_arr = scale_ratios(np_ratios)\n",
    "max_idx = get_max_idx(ratios_df)\n",
    "scaled_arr = scale_ratios_to_max(np_ratios, max_idx)\n",
    "o_ls = average_over_columns(scaled_arr)\n",
    "o_ls = return_rel_abund(o_ls)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(e_ls, o_ls)\n",
    "plt.plot([0,.12],[0,.12])\n",
    "for i, gen_name in enumerate(gen_ls):\n",
    "    plt.annotate(gen_name, (e_ls[i]+.003, o_ls[i]), fontsize=11)\n",
    "plt.show()\n",
    "print(f'\\n{pearsonr(e_ls,o_ls)}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_df.to_csv(os.path.join('./ratios',f'{os.path.basename(current_file)[:-4]}_ratios.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(e_ls,o_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(e_ls, o_ls)\n",
    "# plt.plot([0,.12],[0,.12])\n",
    "plt.plot([0,.0025],[0,.0025])\n",
    "plt.show()\n",
    "print(f'\\n{pearsonr(e_ls,o_ls)}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_to_rel(count_ls):\n",
    "    rel_ls = []\n",
    "    for i in count_ls:\n",
    "        rel_ls.append(i/sum(count_ls))\n",
    "    return rel_ls\n",
    "\n",
    "mean_ls = []\n",
    "median_ls = []\n",
    "\n",
    "for gen in gen_ls:\n",
    "    mean_ls.append(df[df['genome'] == gen]['observed'].mean())\n",
    "    median_ls.append(df[df['genome'] == gen]['observed'].median())\n",
    "\n",
    "mean_ls = count_to_rel(mean_ls)\n",
    "median_ls = count_to_rel(median_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abundances_df = pd.DataFrame()\n",
    "abundances_df['genome'] = gen_ls\n",
    "abundances_df['expected'] = e_ls\n",
    "abundances_df['ratio'] = o_ls\n",
    "abundances_df['mean'] = mean_ls\n",
    "abundances_df['median'] = median_ls\n",
    "abundances_df.to_csv(os.path.join('./ratios',f'{os.path.basename(current_file)[:-4]}_abundances.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = [i for i in range(len(o_ls))]\n",
    "labels = [i for i in gen_ls]\n",
    "\n",
    "a = \"{:.3f}\".format(pearsonr(e_ls,o_ls)[0])\n",
    "b = \"{:.3f}\".format(pearsonr(e_ls,mean_ls)[0])\n",
    "c = \"{:.3f}\".format(pearsonr(e_ls,median_ls)[0])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "# plt.xticks(ticks, labels, rotation = 90)\n",
    "plt.scatter(ticks, e_ls, c='black', marker='_', s=40, alpha=0.45,label='ground truth               pearson r')\n",
    "plt.scatter(ticks, o_ls, c='green', s=20, alpha=0.25,     label=f'ratio estimation          {a}')\n",
    "plt.scatter(ticks, mean_ls, c='orange', s=20, alpha=0.25, label=f'mean depth                {b}')\n",
    "plt.scatter(ticks, median_ls, c='red', s=20, alpha=0.25,  label=f'median depth             {c}')\n",
    "plt.legend()\n",
    "plt.ylabel('relative abundance')\n",
    "plt.xlabel('taxa')\n",
    "plt.savefig(os.path.join('./figures', f'{os.path.basename(current_file)[:-4]}_abundance.tif'), dpi=350)\n",
    "plt.savefig(os.path.join('./figures', f'{os.path.basename(current_file)[:-4]}_abundance.png'), dpi=350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = [i for i in range(len(o_ls))]\n",
    "labels = [i for i in gen_ls]\n",
    "\n",
    "a = \"{:.3f}\".format(pearsonr(e_ls,o_ls)[0])\n",
    "b = \"{:.3f}\".format(pearsonr(e_ls,mean_ls)[0])\n",
    "c = \"{:.3f}\".format(pearsonr(e_ls,median_ls)[0])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "# plt.xticks(ticks, labels, rotation = 90)\n",
    "plt.scatter(ticks, e_ls, c='black', marker='_', s=40, alpha=0.45,label='ground truth               pearson r')\n",
    "plt.scatter(ticks, o_ls, c='green', s=20, alpha=0.25,     label=f'ratio estimation          {a}')\n",
    "plt.scatter(ticks, mean_ls, c='orange', s=20, alpha=0.25, label=f'mean depth                {b}')\n",
    "plt.scatter(ticks, median_ls, c='red', s=20, alpha=0.25,  label=f'median depth             {c}')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylabel('relative abundance (log10)')\n",
    "plt.xlabel('taxa')\n",
    "plt.savefig(os.path.join('./figures', f'log_{os.path.basename(current_file)[:-4]}_abundance.tif'), dpi=350)\n",
    "plt.savefig(os.path.join('./figures', f'log_{os.path.basename(current_file)[:-4]}_abundance.png'), dpi=350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code specifically catered to the Snipen et al. 2021 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dt = {'013372085.1' : 'Acinetobacter baumannii',                               \n",
    "          '000154225.1' : 'Actinomyces odontolyticus',                             \n",
    "          '000008005.1' : 'Bacillus cereus',                                       \n",
    "          '000012825.1' : 'Bacteroides vulgatus',                                  \n",
    "          '000016965.1' : 'Clostridium beijerinckii',                              \n",
    "          '000008565.1' : 'Deinococcus radiodurans',                               \n",
    "          '000172575.2' : 'Enterococcus faecalis',                                 \n",
    "          '000005845.2' : 'Escherichia coli',                                      \n",
    "          '000008525.1' : 'Helicobacter pylori',                                   \n",
    "          '000014425.1' : 'Lactobacillus gasseri',                                 \n",
    "          '000196035.1' : 'Listeria monocytogenes',                                \n",
    "          '000008805.1' : 'Neisseria meningitidis',                                \n",
    "          '000008345.1' : 'Propionibacterium acnes',                               \n",
    "          '000006765.1' : 'Pseudomonas aeruginosa',                                \n",
    "          '000012905.2' : 'Rhodobacter sphaeroides',                               \n",
    "          '000017085.1' : 'Staphylococcus aureus',                                 \n",
    "          '000007645.1' : 'Staphylococcus epidermidis',                            \n",
    "          '000007265.1' : 'Streptococcus agalactiae',                              \n",
    "          '000007465.2' : 'Streptococcus mutans',                                  \n",
    "          '000006885.1' : 'Streptococcus pneumoniae'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = [i for i in range(len(o_ls))]\n",
    "labels = [gen_dt[i.split('_')[1]] for i in gen_ls]\n",
    "labels = [i for i in gen_ls]\n",
    "\n",
    "a = \"{:.3f}\".format(pearsonr(e_ls,o_ls)[0])\n",
    "b = \"{:.3f}\".format(pearsonr(e_ls,mean_ls)[0])\n",
    "c = \"{:.3f}\".format(pearsonr(e_ls,median_ls)[0])\n",
    "\n",
    "plt.figure(figsize=(len(o_ls),10))\n",
    "plt.xticks(ticks, labels, rotation = 90)\n",
    "plt.scatter(ticks, e_ls, c='black', marker='_', s=300, label='ground truth               pearson r')\n",
    "plt.scatter(ticks, o_ls, c='green', s=100, alpha=0.5,     label=f'ratio estimation          {a}')\n",
    "plt.scatter(ticks, mean_ls, c='orange', s=100, alpha=0.5, label=f'mean depth                {b}')\n",
    "plt.scatter(ticks, median_ls, c='red', s=100, alpha=0.5,  label=f'median depth             {c}')\n",
    "plt.legend()\n",
    "plt.ylabel('relative abundance')\n",
    "plt.savefig(os.path.join('./figures', f'{os.path.basename(current_file)[:-4]}_abundance.tif'), dpi=350)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
